{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfFO1EI8TZ/gJUEbi42tsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donggeon2960/CNN-learning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qx4w9dhHZ-VR",
        "outputId": "d7a49428-a70d-41cf-9ac0-baed4060b003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "📚 CNN 교육용 데모 - 실제 신경망으로 이미지 분류 체험\n",
            "🔥 이번에는 진짜 CNN입니다!\n",
            "\n",
            "🎉 진짜 CNN 교육용 데모 시작!\n",
            "==================================================\n",
            "🧠 CNN 모델 생성 완료!\n",
            "\n",
            "📋 CNN 모델 구조:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m319,011\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">319,011</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m319,011\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">319,011</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 레이어별 역할:\n",
            "📌 Conv2D: 특징 추출 (엣지, 패턴 등)\n",
            "📌 MaxPooling2D: 크기 축소 + 중요 특징 선택\n",
            "📌 Flatten: 2D → 1D 변환\n",
            "📌 Dense: 최종 분류 결정\n",
            "📌 Dropout: 과적합 방지\n",
            "\n",
            "🎓 데모용 빠른 훈련 시작...\n",
            "Epoch 1/3\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.3082 - loss: 1.1172\n",
            "Epoch 2/3\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.3967 - loss: 1.0884\n",
            "Epoch 3/3\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3303 - loss: 1.1009\n",
            "✅ 훈련 완료! (실제 프로젝트에서는 실제 데이터 사용)\n",
            "\n",
            "🔍 첫 번째 레이어 필터 시각화\n",
            "필터 개수: 16개\n",
            "필터 크기: 3x3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📸 이미지를 업로드해주세요!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebc5dc5f-31f1-419e-9ee8-4f205a8e783d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ebc5dc5f-31f1-419e-9ee8-4f205a8e783d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 📘 진짜 CNN 교육용 데모 - Google Colab용\n",
        "# 사진 하나 업로드로 CNN 체험하기!\n",
        "\n",
        "# 🔧 필요한 라이브러리 설치\n",
        "!pip install tensorflow matplotlib pillow numpy\n",
        "\n",
        "# 📦 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# 🧠 간단한 CNN 모델 생성\n",
        "def create_simple_cnn():\n",
        "    \"\"\"\n",
        "    교육용 간단한 CNN 모델 생성\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 세 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # Flatten & Dense 레이어\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Animal/Car/Other\n",
        "    ])\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"🧠 CNN 모델 생성 완료!\")\n",
        "    return model\n",
        "\n",
        "# 📊 CNN 구조 시각화\n",
        "def visualize_model_architecture(model):\n",
        "    \"\"\"\n",
        "    CNN 모델 구조를 시각적으로 보여주기\n",
        "    \"\"\"\n",
        "    print(\"\\n📋 CNN 모델 구조:\")\n",
        "    print(\"=\" * 50)\n",
        "    model.summary()\n",
        "\n",
        "    # 레이어별 설명\n",
        "    print(\"\\n🔍 레이어별 역할:\")\n",
        "    print(\"📌 Conv2D: 특징 추출 (엣지, 패턴 등)\")\n",
        "    print(\"📌 MaxPooling2D: 크기 축소 + 중요 특징 선택\")\n",
        "    print(\"📌 Flatten: 2D → 1D 변환\")\n",
        "    print(\"📌 Dense: 최종 분류 결정\")\n",
        "    print(\"📌 Dropout: 과적합 방지\")\n",
        "\n",
        "# 🎲 가짜 데이터로 빠른 훈련\n",
        "def quick_train_with_dummy_data(model):\n",
        "    \"\"\"\n",
        "    데모용 가짜 데이터로 빠른 훈련\n",
        "    \"\"\"\n",
        "    print(\"\\n🎓 데모용 빠른 훈련 시작...\")\n",
        "\n",
        "    # 가짜 훈련 데이터 생성 (200개 샘플)\n",
        "    X_train = np.random.rand(200, 64, 64, 3).astype('float32')\n",
        "    y_train = tf.keras.utils.to_categorical(np.random.randint(0, 3, 200), 3)\n",
        "\n",
        "    # 빠른 훈련 (3 epochs만)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=3,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"✅ 훈련 완료! (실제 프로젝트에서는 실제 데이터 사용)\")\n",
        "    return history\n",
        "\n",
        "# 🔍 CNN 필터 시각화\n",
        "def visualize_cnn_filters(model):\n",
        "    \"\"\"\n",
        "    CNN 첫 번째 레이어의 학습된 필터들 시각화\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어 찾기\n",
        "        first_conv_layer = None\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                first_conv_layer = layer\n",
        "                break\n",
        "\n",
        "        if first_conv_layer is None:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어의 가중치 추출\n",
        "        weights = first_conv_layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            print(\"⚠️ 아직 가중치가 초기화되지 않았습니다.\")\n",
        "            return\n",
        "\n",
        "        filters = weights[0]  # 필터 가중치\n",
        "\n",
        "        print(f\"\\n🔍 첫 번째 레이어 필터 시각화\")\n",
        "        print(f\"필터 개수: {filters.shape[3]}개\")\n",
        "        print(f\"필터 크기: {filters.shape[0]}x{filters.shape[1]}\")\n",
        "\n",
        "        # 필터 중 처음 8개만 시각화\n",
        "        num_filters_to_show = min(8, filters.shape[3])\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "        fig.suptitle('CNN Learned Filters (First Layer)', fontsize=16)\n",
        "\n",
        "        for i in range(num_filters_to_show):\n",
        "            ax = axes[i // 4, i % 4]\n",
        "\n",
        "            # 필터를 시각화하기 위해 정규화\n",
        "            filter_img = filters[:, :, 0, i]  # 첫 번째 채널의 i번째 필터\n",
        "\n",
        "            # 정규화 (0-1 범위로)\n",
        "            if filter_img.max() > filter_img.min():\n",
        "                filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min())\n",
        "\n",
        "            ax.imshow(filter_img, cmap='viridis')\n",
        "            ax.set_title(f'Filter {i+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 필터 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 가중치 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")\n",
        "\n",
        "# 📸 이미지 업로드 및 전처리\n",
        "def upload_and_preprocess_image():\n",
        "    \"\"\"\n",
        "    이미지 업로드 및 CNN 입력용 전처리\n",
        "    \"\"\"\n",
        "    print(\"📸 이미지를 업로드해주세요!\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    image_data = uploaded[filename]\n",
        "\n",
        "    # 이미지 로드 및 전처리\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # RGB로 변환 (RGBA인 경우)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    # 크기 조정 (64x64)\n",
        "    image_resized = image.resize((64, 64))\n",
        "\n",
        "    # 배열로 변환 및 정규화\n",
        "    image_array = np.array(image_resized).astype('float32') / 255.0\n",
        "\n",
        "    # 배치 차원 추가 (1, 64, 64, 3)\n",
        "    image_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    return image, image_resized, image_batch, filename\n",
        "\n",
        "# 🎯 CNN 예측 및 결과 시각화\n",
        "def predict_and_visualize(model, original_img, processed_img, image_batch, filename):\n",
        "    \"\"\"\n",
        "    CNN으로 예측하고 결과 시각화\n",
        "    \"\"\"\n",
        "    # 클래스 라벨 정의\n",
        "    class_names = ['Animal', 'Car', 'Other']\n",
        "\n",
        "    # CNN 예측\n",
        "    predictions = model.predict(image_batch, verbose=0)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class]\n",
        "\n",
        "    # 결과 시각화\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 원본 이미지\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title(f'original image\\n({filename})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 전처리된 이미지 (CNN 입력)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(processed_img)\n",
        "    plt.title('CNN input image\\n(64x64 크기 조정)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 예측 결과\n",
        "    plt.subplot(1, 3, 3)\n",
        "    bars = plt.bar(class_names, predictions[0])\n",
        "    bars[predicted_class].set_color('red')  # 최고 확률 클래스 강조\n",
        "    plt.title(f'CNN Prediction Results\\nPrediction: {class_names[predicted_class]} ({confidence:.2%})')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # 확률 값 표시\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        plt.text(i, prob + 0.02, f'{prob:.2%}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 결과 출력\n",
        "    print(\"\\n🎯 CNN Prediction Results:\")\n",
        "    print(\"=\" * 30)\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        marker = \"👉\" if i == predicted_class else \"  \"\n",
        "        print(f\"{marker} {name}: {prob:.2%}\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"Final Prediction: {class_names[predicted_class]} (Confidence: {confidence:.2%})\")\n",
        "\n",
        "# 🔬 CNN 중간 레이어 활성화 시각화\n",
        "def visualize_intermediate_activations(model, image_batch):\n",
        "    \"\"\"\n",
        "    CNN 중간 레이어들의 활성화 맵 시각화\n",
        "    \"\"\"\n",
        "    print(\"\\n🔬 CNN 내부 작동 과정 시각화...\")\n",
        "\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            # 더미 데이터로 모델 빌드\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # Conv2D 레이어만 찾기\n",
        "        conv_layers = []\n",
        "        layer_names = []\n",
        "\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                conv_layers.append(layer)\n",
        "                layer_names.append(f'Conv2D Layer {len(conv_layers)}')\n",
        "\n",
        "        if len(conv_layers) == 0:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 중간 레이어 출력을 위한 모델 생성\n",
        "        layer_outputs = [layer.output for layer in conv_layers]\n",
        "        activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "        # 활성화 맵 계산\n",
        "        activations = activation_model.predict(image_batch, verbose=0)\n",
        "\n",
        "        # 단일 출력인 경우 리스트로 변환\n",
        "        if not isinstance(activations, list):\n",
        "            activations = [activations]\n",
        "\n",
        "        # 시각화\n",
        "        num_layers = min(3, len(conv_layers))  # 최대 3개 레이어만\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            activation = activations[i]\n",
        "            layer_name = layer_names[i]\n",
        "\n",
        "            # 처음 4개 필터만 표시\n",
        "            num_filters = min(4, activation.shape[-1])\n",
        "            for j in range(num_filters):\n",
        "                plt.subplot(num_layers, 4, i*4 + j + 1)\n",
        "\n",
        "                # 활성화 맵 정규화\n",
        "                feature_map = activation[0, :, :, j]\n",
        "                if feature_map.max() > feature_map.min():\n",
        "                    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
        "\n",
        "                plt.imshow(feature_map, cmap='viridis')\n",
        "                plt.title(f'{layer_name}\\nFilter {j+1}')\n",
        "                plt.axis('off')\n",
        "\n",
        "        plt.suptitle('CNN Feature Maps - How CNN \"Sees\" Your Image', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"💡 해석:\")\n",
        "        print(\"- 첫 번째 레이어: 기본적인 엣지, 색상 검출\")\n",
        "        print(\"- 두 번째 레이어: 더 복잡한 패턴 조합\")\n",
        "        print(\"- 세 번째 레이어: 고수준 특징 (객체 부분)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 활성화 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 TensorFlow 버전 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")\n",
        "\n",
        "# 🎮 메인 실행 함수\n",
        "def run_cnn_demo():\n",
        "    \"\"\"\n",
        "    CNN 교육용 데모 메인 실행\n",
        "    \"\"\"\n",
        "    print(\"🎉 진짜 CNN 교육용 데모 시작!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. CNN 모델 생성\n",
        "    model = create_simple_cnn()\n",
        "\n",
        "    # 2. 모델 구조 확인\n",
        "    visualize_model_architecture(model)\n",
        "\n",
        "    # 3. 빠른 훈련 (데모용)\n",
        "    history = quick_train_with_dummy_data(model)\n",
        "\n",
        "    # 4. 학습된 필터 시각화\n",
        "    visualize_cnn_filters(model)\n",
        "\n",
        "    # 5. 이미지 업로드 및 예측\n",
        "    original_img, processed_img, image_batch, filename = upload_and_preprocess_image()\n",
        "\n",
        "    # 6. CNN 예측 및 결과 시각화\n",
        "    predict_and_visualize(model, original_img, processed_img, image_batch, filename)\n",
        "\n",
        "    # 7. CNN 내부 작동 과정 시각화\n",
        "    visualize_intermediate_activations(model, image_batch)\n",
        "\n",
        "    print(\"\\n🎓 CNN 데모 완료!\")\n",
        "    print(\"💡 이제 CNN이 어떻게 이미지를 '이해'하는지 보셨습니다!\")\n",
        "\n",
        "# 🚀 데모 실행\n",
        "print(\"📚 CNN 교육용 데모 - 실제 신경망으로 이미지 분류 체험\")\n",
        "print(\"🔥 이번에는 진짜 CNN입니다!\")\n",
        "print()\n",
        "run_cnn_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 교육용 데모 코드 분석\n",
        "\n",
        "## 📋 개요\n",
        "\n",
        "이 코드는 **Google Colab 환경에서 실행되는 CNN(Convolutional Neural Network) 교육용 데모**입니다. 사용자가 직접 이미지를 업로드하여 CNN의 작동 원리를 체험할 수 있도록 설계되었습니다.\n",
        "\n",
        "## 🏗️ 전체 구조\n",
        "\n",
        "### 라이브러리 및 환경 설정\n",
        "```python\n",
        "!pip install tensorflow matplotlib pillow numpy\n",
        "```\n",
        "- **TensorFlow**: 딥러닝 프레임워크\n",
        "- **Matplotlib**: 시각화 라이브러리\n",
        "- **Pillow**: 이미지 처리 라이브러리\n",
        "- **NumPy**: 수치 연산 라이브러리\n",
        "\n",
        "## 🔧 핵심 함수 분석\n",
        "\n",
        "### 1. `create_simple_cnn()` - CNN 모델 생성\n",
        "\n",
        "**모델 구조:**\n",
        "- **입력층**: 64×64×3 (RGB 이미지)\n",
        "- **Conv2D Layer 1**: 16개 필터, 3×3 커널, ReLU 활성화\n",
        "- **MaxPooling2D**: 2×2 풀링\n",
        "- **Conv2D Layer 2**: 32개 필터, 3×3 커널, ReLU 활성화\n",
        "- **MaxPooling2D**: 2×2 풀링\n",
        "- **Conv2D Layer 3**: 64개 필터, 3×3 커널, ReLU 활성화\n",
        "- **MaxPooling2D**: 2×2 풀링\n",
        "- **Flatten**: 2D → 1D 변환\n",
        "- **Dense**: 128개 뉴런, ReLU 활성화\n",
        "- **Dropout**: 0.5 (과적합 방지)\n",
        "- **출력층**: 3개 클래스 (Animal/Car/Other), Softmax 활성화\n",
        "\n",
        "**특징:**\n",
        "- 점진적 필터 증가 (16→32→64)로 계층적 특징 추출\n",
        "- Adam 옵티마이저와 categorical_crossentropy 손실 함수 사용\n",
        "\n",
        "### 2. `visualize_model_architecture()` - 모델 구조 시각화\n",
        "\n",
        "**기능:**\n",
        "- `model.summary()`로 레이어별 파라미터 수 표시\n",
        "- 각 레이어의 역할 설명 제공\n",
        "\n",
        "**출력 내용:**\n",
        "- Conv2D: 특징 추출 (엣지, 패턴 등)\n",
        "- MaxPooling2D: 크기 축소 + 중요 특징 선택\n",
        "- Flatten: 2D → 1D 변환\n",
        "- Dense: 최종 분류 결정\n",
        "- Dropout: 과적합 방지\n",
        "\n",
        "### 3. `quick_train_with_dummy_data()` - 데모용 빠른 훈련\n",
        "\n",
        "**데이터 생성:**\n",
        "```python\n",
        "X_train = np.random.rand(200, 64, 64, 3).astype('float32')\n",
        "y_train = tf.keras.utils.to_categorical(np.random.randint(0, 3, 200), 3)\n",
        "```\n",
        "\n",
        "**훈련 설정:**\n",
        "- 샘플 수: 200개\n",
        "- 에포크: 3회\n",
        "- 배치 크기: 32\n",
        "\n",
        "**주의사항:**\n",
        "- 가짜 데이터로 훈련하므로 실제 분류 성능은 무의미\n",
        "- 교육 목적으로만 사용\n",
        "\n",
        "### 4. `visualize_cnn_filters()` - 학습된 필터 시각화\n",
        "\n",
        "**기능:**\n",
        "- 첫 번째 Conv2D 레이어의 학습된 필터 8개 시각화\n",
        "- 필터가 학습한 패턴을 viridis 컬러맵으로 표시\n",
        "\n",
        "**과정:**\n",
        "1. 첫 번째 Conv2D 레이어 탐지\n",
        "2. 가중치 추출\n",
        "3. 필터 정규화 (0-1 범위)\n",
        "4. 2×4 그리드로 시각화\n",
        "\n",
        "### 5. `upload_and_preprocess_image()` - 이미지 업로드 및 전처리\n",
        "\n",
        "**처리 과정:**\n",
        "1. Google Colab 파일 업로드 기능 활용\n",
        "2. RGB 변환 (RGBA인 경우)\n",
        "3. 64×64 크기 조정\n",
        "4. 배열 변환 및 정규화 (0-1 범위)\n",
        "5. 배치 차원 추가 (1, 64, 64, 3)\n",
        "\n",
        "**반환값:**\n",
        "- 원본 이미지\n",
        "- 전처리된 이미지\n",
        "- 배치 형태 이미지\n",
        "- 파일명\n",
        "\n",
        "### 6. `predict_and_visualize()` - 예측 및 결과 시각화\n",
        "\n",
        "**시각화 구성:**\n",
        "- **subplot 1**: 원본 이미지\n",
        "- **subplot 2**: 전처리된 이미지 (CNN 입력)\n",
        "- **subplot 3**: 예측 결과 (막대 그래프)\n",
        "\n",
        "**출력 정보:**\n",
        "- 각 클래스별 확률\n",
        "- 최종 예측 결과\n",
        "- 신뢰도 (confidence)\n",
        "\n",
        "### 7. `visualize_intermediate_activations()` - 중간 레이어 활성화 맵\n",
        "\n",
        "**기능:**\n",
        "- CNN 내부에서 이미지가 어떻게 처리되는지 시각화\n",
        "- 각 Conv2D 레이어의 처음 4개 필터 활성화 맵 표시\n",
        "\n",
        "**시각화 내용:**\n",
        "- 첫 번째 레이어: 기본적인 엣지, 색상 검출\n",
        "- 두 번째 레이어: 더 복잡한 패턴 조합\n",
        "- 세 번째 레이어: 고수준 특징 (객체 부분)\n",
        "\n",
        "## 🎮 메인 실행 흐름\n",
        "\n",
        "### `run_cnn_demo()` 함수 실행 순서:\n",
        "\n",
        "1. **모델 생성**: CNN 아키텍처 구성\n",
        "2. **구조 확인**: 모델 레이어 및 파라미터 정보 출력\n",
        "3. **빠른 훈련**: 가짜 데이터로 데모용 훈련\n",
        "4. **필터 시각화**: 학습된 필터 패턴 확인\n",
        "5. **이미지 업로드**: 사용자 이미지 입력 및 전처리\n",
        "6. **예측 수행**: CNN으로 이미지 분류 및 결과 시각화\n",
        "7. **내부 분석**: 중간 레이어 활성화 맵 시각화\n",
        "\n",
        "## 🎯 교육적 가치\n",
        "\n",
        "### ✅ 강점\n",
        "\n",
        "1. **실제 CNN 구현**\n",
        "   - 이론이 아닌 실제 작동하는 신경망 체험\n",
        "   - TensorFlow/Keras를 사용한 표준적인 구현\n",
        "\n",
        "2. **단계별 시각화**\n",
        "   - 모델 구조 → 필터 → 활성화 맵 → 예측 결과\n",
        "   - CNN의 작동 원리를 직관적으로 이해\n",
        "\n",
        "3. **인터랙티브 학습**\n",
        "   - 사용자가 직접 이미지를 업로드하여 체험\n",
        "   - 즉각적인 피드백과 결과 확인\n",
        "\n",
        "4. **완전한 파이프라인**\n",
        "   - 데이터 전처리부터 결과 해석까지 전 과정 포함\n",
        "   - 실제 머신러닝 프로젝트의 워크플로우 학습\n",
        "\n",
        "### ⚠️ 한계점\n",
        "\n",
        "1. **가짜 데이터 훈련**\n",
        "   - 랜덤 데이터로 훈련하므로 실제 분류 성능은 무의미\n",
        "   - 교육 목적으로만 적합\n",
        "\n",
        "2. **과도한 간소화**\n",
        "   - 64×64 해상도로 제한\n",
        "   - 3개 클래스만 지원\n",
        "   - 실제 성능은 기대하기 어려움\n",
        "\n",
        "3. **에러 처리**\n",
        "   - 일부 시각화 함수에서 예외 발생 가능\n",
        "   - TensorFlow 버전 호환성 이슈 가능\n",
        "\n",
        "4. **제한된 환경**\n",
        "   - Google Colab 전용\n",
        "   - 로컬 환경에서는 수정 필요\n",
        "\n",
        "## 🚀 활용 방안\n",
        "\n",
        "### 교육 목적\n",
        "- CNN 기본 개념 학습\n",
        "- 딥러닝 파이프라인 이해\n",
        "- 시각화를 통한 직관적 학습\n",
        "\n",
        "### 확장 가능성\n",
        "- 실제 데이터셋 적용 (CIFAR-10, ImageNet 등)\n",
        "- 더 복잡한 모델 구조 실험\n",
        "- 다양한 전처리 기법 적용\n",
        "- 성능 평가 지표 추가\n",
        "\n",
        "## 📚 학습 포인트\n",
        "\n",
        "1. **CNN 구조 이해**: 컨볼루션 → 풀링 → 완전연결층 구조\n",
        "2. **시각화의 중요성**: 블랙박스 모델의 내부 작동 이해\n",
        "3. **전처리의 필요성**: 이미지 크기 조정, 정규화 등\n",
        "4. **과적합 방지**: Dropout, 적절한 모델 복잡도\n",
        "5. **실무 워크플로우**: 모델 생성 → 훈련 → 평가 → 시각화\n",
        "\n",
        "이 코드는 CNN의 작동 원리를 **체험적으로 학습**할 수 있는 훌륭한 교육 도구입니다. 특히 \"CNN이 이미지를 어떻게 '이해'하는가\"를 시각적으로 보여주는 점이 매우 효과적입니다."
      ],
      "metadata": {
        "id": "6lNuv-B_jJGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReLU와 SoftMax 활성화 함수 가이드\n",
        "\n",
        "## 📋 활성화 함수란?\n",
        "\n",
        "활성화 함수(Activation Function)는 신경망에서 각 뉴런의 출력을 결정하는 함수입니다. 입력 신호를 받아 특정 규칙에 따라 출력을 생성하며, 신경망이 비선형성을 학습할 수 있게 해주는 핵심 요소입니다.\n",
        "\n",
        "## 🔥 ReLU (Rectified Linear Unit)\n",
        "\n",
        "### 정의\n",
        "ReLU는 **가장 널리 사용되는 활성화 함수** 중 하나로, 음수 값은 0으로, 양수 값은 그대로 출력하는 함수입니다.\n",
        "\n",
        "### 수학적 표현\n",
        "```\n",
        "f(x) = max(0, x)\n",
        "```\n",
        "\n",
        "또는\n",
        "\n",
        "```\n",
        "f(x) = { x  if x > 0\n",
        "        { 0  if x ≤ 0\n",
        "```\n",
        "\n",
        "### 그래프 형태\n",
        "```\n",
        "    |\n",
        "  5 |     /\n",
        "    |    /\n",
        "  4 |   /\n",
        "    |  /\n",
        "  3 | /\n",
        "    |/\n",
        "  2 |\n",
        "    |\n",
        "  1 |\n",
        "    |\n",
        "----+----+----+----+----\n",
        " -2 | 0  1    2    3    4\n",
        "    |\n",
        "```\n",
        "\n",
        "### 특징\n",
        "\n",
        "#### ✅ 장점\n",
        "1. **계산 효율성**\n",
        "   - 단순한 수식으로 매우 빠른 연산\n",
        "   - 미분도 간단 (x > 0일 때 1, x ≤ 0일 때 0)\n",
        "\n",
        "2. **그래디언트 소실 문제 해결**\n",
        "   - 양수 구간에서 그래디언트가 1로 일정\n",
        "   - 깊은 신경망에서도 학습이 잘 됨\n",
        "\n",
        "3. **희소성(Sparsity)**\n",
        "   - 음수 입력에 대해 0 출력\n",
        "   - 네트워크의 희소성 증가로 효율적 표현\n",
        "\n",
        "#### ⚠️ 단점\n",
        "1. **죽은 ReLU 문제 (Dead ReLU)**\n",
        "   - 음수 구간에서 그래디언트가 0\n",
        "   - 일부 뉴런이 영구적으로 비활성화될 수 있음\n",
        "\n",
        "2. **출력 범위 제한 없음**\n",
        "   - 양수 구간에서 무한대까지 출력 가능\n",
        "   - 때로는 출력값이 너무 커질 수 있음\n",
        "\n",
        "### 사용 예시 (Python)\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# 예시 데이터\n",
        "x = np.linspace(-5, 5, 100)\n",
        "y = relu(x)\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.plot(x, y)\n",
        "plt.title('ReLU Function')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Output')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 변형 버전들\n",
        "- **Leaky ReLU**: f(x) = max(0.01x, x)\n",
        "- **ELU**: 지수 선형 단위\n",
        "- **Swish**: f(x) = x * sigmoid(x)\n",
        "\n",
        "## 🎯 SoftMax\n",
        "\n",
        "### 정의\n",
        "SoftMax는 **다중 클래스 분류의 출력층**에서 사용되는 활성화 함수로, 여러 값을 확률 분포로 변환합니다.\n",
        "\n",
        "### 수학적 표현\n",
        "벡터 **z** = [z₁, z₂, ..., zₙ]에 대해:\n",
        "\n",
        "```\n",
        "softmax(z)ᵢ = e^(zᵢ) / Σ(j=1 to n) e^(zⱼ)\n",
        "```\n",
        "\n",
        "### 특징\n",
        "\n",
        "#### ✅ 장점\n",
        "1. **확률 분포 생성**\n",
        "   - 모든 출력값의 합이 1\n",
        "   - 각 값이 0과 1 사이의 확률값\n",
        "\n",
        "2. **다중 클래스 분류 최적화**\n",
        "   - 가장 높은 값을 가진 클래스를 예측\n",
        "   - 확률적 해석이 가능\n",
        "\n",
        "3. **미분 가능**\n",
        "   - 역전파 알고리즘에 적합\n",
        "   - 연속적이고 부드러운 함수\n",
        "\n",
        "#### ⚠️ 단점\n",
        "1. **계산 복잡도**\n",
        "   - 지수 함수 계산으로 ReLU보다 느림\n",
        "   - 수치적 안정성 문제 가능\n",
        "\n",
        "2. **출력층에만 적합**\n",
        "   - 은닉층에서는 그래디언트 소실 문제\n",
        "   - 주로 최종 분류 단계에서만 사용\n",
        "\n",
        "### 동작 원리\n",
        "\n",
        "#### 예시 1: 3개 클래스 분류\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z))  # 수치 안정성을 위한 정규화\n",
        "    return exp_z / np.sum(exp_z)\n",
        "\n",
        "# 예시 로짓 값\n",
        "logits = np.array([2.0, 1.0, 0.1])\n",
        "probabilities = softmax(logits)\n",
        "\n",
        "print(\"로짓 값:\", logits)\n",
        "print(\"확률값:\", probabilities)\n",
        "print(\"확률 합:\", np.sum(probabilities))\n",
        "```\n",
        "\n",
        "**출력:**\n",
        "```\n",
        "로짓 값: [2.0 1.0 0.1]\n",
        "확률값: [0.659 0.242 0.099]\n",
        "확률 합: 1.0\n",
        "```\n",
        "\n",
        "#### 예시 2: 온도 매개변수\n",
        "```python\n",
        "def softmax_with_temperature(z, temperature=1.0):\n",
        "    z_temp = z / temperature\n",
        "    exp_z = np.exp(z_temp - np.max(z_temp))\n",
        "    return exp_z / np.sum(exp_z)\n",
        "\n",
        "logits = np.array([2.0, 1.0, 0.1])\n",
        "\n",
        "# 낮은 온도 (더 확실한 예측)\n",
        "print(\"T=0.5:\", softmax_with_temperature(logits, 0.5))\n",
        "# 높은 온도 (더 균등한 예측)\n",
        "print(\"T=2.0:\", softmax_with_temperature(logits, 2.0))\n",
        "```\n",
        "\n",
        "## 🔗 ReLU와 SoftMax의 관계\n",
        "\n",
        "### 신경망에서의 역할 분담\n",
        "\n",
        "```\n",
        "입력 → [은닉층 + ReLU] → [은닉층 + ReLU] → [출력층 + SoftMax] → 예측\n",
        "```\n",
        "\n",
        "1. **ReLU (은닉층)**\n",
        "   - 특징 추출 및 비선형 변환\n",
        "   - 빠른 학습과 효율적 연산\n",
        "   - 복잡한 패턴 학습\n",
        "\n",
        "2. **SoftMax (출력층)**\n",
        "   - 최종 분류 결정\n",
        "   - 확률 분포 생성\n",
        "   - 해석 가능한 결과 제공\n",
        "\n",
        "### CNN에서의 적용 예시\n",
        "```python\n",
        "model = tf.keras.Sequential([\n",
        "    # 컨볼루션 레이어들 (ReLU 사용)\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    # 완전연결층 (ReLU 사용)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    \n",
        "    # 출력층 (SoftMax 사용)\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # 3개 클래스\n",
        "])\n",
        "```\n",
        "\n",
        "## 📊 실제 적용 시 고려사항\n",
        "\n",
        "### ReLU 사용 시\n",
        "- **초기화**: He 초기화 방법 권장\n",
        "- **학습률**: 적절한 학습률 설정으로 죽은 ReLU 방지\n",
        "- **배치 정규화**: 함께 사용하면 효과적\n",
        "\n",
        "### SoftMax 사용 시\n",
        "- **수치 안정성**: 로짓에서 최댓값 빼기\n",
        "- **손실 함수**: Categorical Crossentropy와 함께 사용\n",
        "- **온도 조절**: 모델 신뢰도 조절 가능\n",
        "\n",
        "## 🎓 학습 포인트\n",
        "\n",
        "1. **ReLU**: 은닉층에서 빠르고 효과적인 비선형 변환\n",
        "2. **SoftMax**: 출력층에서 확률 분포 생성\n",
        "3. **상호 보완**: ReLU의 효율성 + SoftMax의 해석성\n",
        "4. **실무 적용**: 대부분의 분류 모델에서 표준적으로 사용\n",
        "\n",
        "이 두 활성화 함수를 이해하면 현대 딥러닝 모델의 핵심 작동 원리를 파악할 수 있습니다!"
      ],
      "metadata": {
        "id": "V4Du8tHfjc2n"
      }
    }
  ]
}